<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Analizador de Onsets con Meyda.js</title>
    <script src="https://cdn.jsdelivr.net/npm/meyda@5.6.3/dist/web/meyda.min.js"></script>
    <style>
        body {
            font-family: sans-serif;
            background-color: #f0f0f0;
            color: #333;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        #controls, #status, #visualizer {
            margin: 10px 0;
            padding: 15px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            text-align: center;
        }
        #visualizer {
            min-height: 100px;
            width: 80%;
            max-width: 600px;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 2em;
            font-weight: bold;
            transition: background-color 0.1s ease-out; /* Suave transición de color */
        }
        .onset-display {
             /* Se mostrará texto directamente en #visualizer */
        }
        .grave {
            color: blue;
        }
        .agudo {
            color: red;
        }
         button {
            padding: 10px 15px;
            font-size: 1em;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.2s;
         }
         button:hover {
             background-color: #0056b3;
         }
         button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
         }
         input[type="file"] {
             margin-bottom: 10px;
         }
    </style>
</head>
<body>

    <h1>Analizador de Onsets Agudos/Graves</h1>

    <div id="controls">
        <input type="file" id="audioFile" accept="audio/mp3, audio/wav, audio/ogg">
        <button id="analyzeButton" disabled>Analizar y Reproducir</button>
    </div>

    <div id="status">Sube un archivo MP3, WAV u OGG.</div>

    <div id="visualizer">
        <span id="onsetIndicator"></span>
    </div>

    <audio id="audioPlayer" style="display: none;"></audio>
                        
        <script>
    document.addEventListener('DOMContentLoaded', (event) => {
        // *** Mensaje de prueba inicial ***
        console.log("Dentro de DOMContentLoaded. ¿Existe Meyda?:", window.Meyda);
        // ********************************

        const audioFile = document.getElementById('audioFile');
        const analyzeButton = document.getElementById('analyzeButton');
        const statusDiv = document.getElementById('status');
        const visualizerDiv = document.getElementById('visualizer');
        const onsetIndicator = document.getElementById('onsetIndicator');
        const audioPlayer = document.getElementById('audioPlayer'); // No usado activamente para play, pero referenciado

        let audioContext;
        let audioBuffer;
        let detectedOnsets = [];
        let meydaAnalyzer;
        let sourceNode;
        let animationFrameId;

        // --- Parámetros Ajustables ---
        // Generales
        const SPECTRAL_CENTROID_THRESHOLD = 1000; // Hz. Umbral Agudo/Grave (BAJAR si no detecta agudos)
        const MEYDA_BUFFER_SIZE = 1024;
        const DISPLAY_DURATION = 150; // ms
        const DEBOUNCE_TIME = 0.075; // (Segundos) Tiempo mínimo entre onsets detectados (75ms)

        // Para detección ESTÁNDAR (más estricta, para golpes principales)
        const RMS_THRESHOLD = 0.03; // Umbral RMS mínimo (SUBIR si hay demasiados onsets)
        const PEAK_MULTIPLIER = 2.0; // Factor de pico sobre RMS anterior (SUBIR si hay demasiados onsets)

        // Para detección SENSIBLE de AGUDOS (más permisiva, para intentar capturar agudos débiles)
        const AGUDO_RMS_THRESHOLD = 0.018; // Umbral RMS más bajo para agudos (AJUSTAR)
        const AGUDO_PEAK_MULTIPLIER = 1.4; // Multiplicador de pico más bajo para agudos (AJUSTAR)
        // --------------------------


        function initAudioContext() {
            if (!audioContext) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log("AudioContext iniciado.");
                } catch (e) {
                    statusDiv.textContent = 'Error: La Web Audio API no es soportada por este navegador.';
                    console.error(e);
                }
            }
        }

        audioFile.addEventListener('change', () => {
            initAudioContext();
            if (audioFile.files.length > 0 && audioContext) {
                analyzeButton.disabled = false;
                statusDiv.textContent = 'Archivo listo para analizar.';
            } else {
                analyzeButton.disabled = true;
            }
        });

        analyzeButton.addEventListener('click', async () => {
            if (!audioFile.files.length || !audioContext) return;
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            analyzeButton.disabled = true;
            statusDiv.textContent = 'Leyendo archivo...';
            const file = audioFile.files[0];
            const reader = new FileReader();

            reader.onload = async (e) => {
                try {
                    statusDiv.textContent = 'Decodificando audio...';
                    audioBuffer = await audioContext.decodeAudioData(e.target.result);
                    statusDiv.textContent = 'Audio decodificado. Analizando onsets...';
                    await analyzeOnsets(); // Contiene la lógica de Meyda ahora modificada
                    statusDiv.textContent = `Análisis completo. ${detectedOnsets.length} onsets detectados. Reproduciendo...`;
                    console.log("Onsets detectados:", detectedOnsets);
                    startPlaybackAndVisualization();
                } catch (error) {
                    statusDiv.textContent = `Error procesando el audio: ${error.message}`;
                    console.error('Error en reader.onload:', error);
                    analyzeButton.disabled = false;
                }
            };
            reader.onerror = (error) => {
                statusDiv.textContent = 'Error leyendo el archivo.';
                console.error('Error FileReader:', error);
                analyzeButton.disabled = false;
            };
            reader.readAsArrayBuffer(file);
        });

        async function analyzeOnsets() {
            detectedOnsets = [];
            if (!audioBuffer) return;

            const offlineContext = new OfflineAudioContext(
                audioBuffer.numberOfChannels,
                audioBuffer.length,
                audioBuffer.sampleRate
            );
            const offlineSource = offlineContext.createBufferSource();
            offlineSource.buffer = audioBuffer;

            try {
                console.log("Intentando crear MeydaAnalyzer...");
                meydaAnalyzer = Meyda.createMeydaAnalyzer({
                    audioContext: offlineContext,
                    source: offlineSource,
                    bufferSize: MEYDA_BUFFER_SIZE,
                    featureExtractors: ["rms", "spectralCentroid"], // Características necesarias
                    callback: features => {
                        // --- Inicio Lógica de Detección Paralela ---
                        if (typeof meydaAnalyzer.lastRms === 'undefined') {
                            meydaAnalyzer.lastRms = 0;
                        }
                        const currentRms = features.rms;
                        const spectralCentroid = features.spectralCentroid;
                        // Calcula el timestamp una sola vez por frame
                        const timestamp = (meydaAnalyzer.framesElapsed * MEYDA_BUFFER_SIZE) / audioBuffer.sampleRate;
                        let detectedThisFrame = null; // Variable para guardar si se detectó algo

                        // CHECK 1: Detección Estándar (Umbrales más altos)
                        if (currentRms > RMS_THRESHOLD && currentRms > meydaAnalyzer.lastRms * PEAK_MULTIPLIER) {
                            const onsetType = spectralCentroid > SPECTRAL_CENTROID_THRESHOLD ? 'agudo' : 'grave';
                            console.log(`Onset Estándar -> Tipo: ${onsetType}, RMS: ${currentRms.toFixed(3)}, Centroide: ${spectralCentroid.toFixed(0)} @${timestamp.toFixed(2)}s`);
                            detectedThisFrame = { timestamp: timestamp, type: onsetType };
                        }
                        // CHECK 2: Detección Sensible SOLO para Agudos (si no se detectó antes y cumple condiciones)
                        else if (currentRms > AGUDO_RMS_THRESHOLD &&
                                 currentRms > meydaAnalyzer.lastRms * AGUDO_PEAK_MULTIPLIER &&
                                 spectralCentroid > SPECTRAL_CENTROID_THRESHOLD) { // Solo si es agudo

                            console.log(`Onset Agudo Sensible -> RMS: ${currentRms.toFixed(3)}, Centroide: ${spectralCentroid.toFixed(0)} @${timestamp.toFixed(2)}s`);
                            detectedThisFrame = { timestamp: timestamp, type: 'agudo' };
                        }

                        // Aplicar Debounce y guardar si se detectó algo en este frame
                        if (detectedThisFrame) {
                            const lastOnset = detectedOnsets[detectedOnsets.length - 1];
                            // Comprueba contra el último onset añadido, sin importar cómo se detectó
                            if (!lastOnset || detectedThisFrame.timestamp > lastOnset.timestamp + DEBOUNCE_TIME) {
                                detectedOnsets.push(detectedThisFrame);
                            } else {
                                // Opcional: Log para ver onsets descartados por debounce
                                // console.log(`Onset descartado por debounce @${detectedThisFrame.timestamp.toFixed(2)}s`);
                            }
                        }

                        meydaAnalyzer.lastRms = currentRms; // Actualizar para el próximo frame
                        meydaAnalyzer.framesElapsed = (meydaAnalyzer.framesElapsed || 0) + 1;
                         // --- Fin Lógica de Detección ---
                    }
                });
                console.log("MeydaAnalyzer creado con éxito.");

            } catch (e) {
                console.error("ERROR al crear MeydaAnalyzer:", e);
                statusDiv.textContent = "Error fatal: Fallo al inicializar Meyda.";
                throw e;
            }

            meydaAnalyzer.start();
            offlineSource.start(0);

            return offlineContext.startRendering().then(() => {
                meydaAnalyzer.stop();
                console.log("Análisis offline completado.");
            }).catch(err => {
                console.error("Error durante el análisis offline:", err);
                statusDiv.textContent = 'Error durante el análisis offline.';
            });
        }

        function startPlaybackAndVisualization() {
            if (sourceNode) {
                try { sourceNode.stop(); } catch(e) {}
            }
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }

            sourceNode = audioContext.createBufferSource();
            sourceNode.buffer = audioBuffer;
            sourceNode.connect(audioContext.destination);

            const startTime = audioContext.currentTime;
            let onsetIndex = 0;

            function visualizationLoop() {
                if (!sourceNode) return;

                const elapsedTime = audioContext.currentTime - startTime;

                // Muestra onsets mientras su tiempo sea menor o igual al tiempo de reproducción
                while (onsetIndex < detectedOnsets.length && detectedOnsets[onsetIndex].timestamp <= elapsedTime) {
                    const onset = detectedOnsets[onsetIndex];

                    // Mostrar el indicador visual
                    onsetIndicator.textContent = onset.type.toUpperCase();
                    onsetIndicator.className = `onset-display ${onset.type}`;
                    visualizerDiv.style.backgroundColor = onset.type === 'grave' ? 'rgba(0, 0, 255, 0.2)' : 'rgba(255, 0, 0, 0.2)';

                    // Limpiar el indicador después de un tiempo
                    // Usamos una IIFE (Immediately Invoked Function Expression) para capturar el índice correcto
                    // o simplemente confiamos en que setTimeout es lo suficientemente rápido (generalmente lo es)
                    // Para seguridad, podríamos pasar el índice o el propio onset al timeout si hubiera problemas.
                    setTimeout(() => {
                        // Solo limpiar si NO hay otro onset esperando inmediatamente
                         const nextOnsetIndex = onsetIndex; // El índice ya se habrá incrementado si este fue el último procesado en el while
                         const currentTimeCheck = audioContext.currentTime - startTime;
                         if (nextOnsetIndex >= detectedOnsets.length || detectedOnsets[nextOnsetIndex].timestamp > currentTimeCheck) {
                            onsetIndicator.textContent = '';
                            onsetIndicator.className = 'onset-display';
                            visualizerDiv.style.backgroundColor = '#fff';
                         }
                    }, DISPLAY_DURATION);

                    onsetIndex++; // Avanzar al siguiente onset detectado
                }


                // Continuar el bucle si la reproducción no ha terminado
                if (elapsedTime < audioBuffer.duration + 0.1) { // Añadimos un pequeño margen
                    animationFrameId = requestAnimationFrame(visualizationLoop);
                } else {
                     // Limpieza final explícita al terminar la duración del buffer
                     statusDiv.textContent = 'Reproducción finalizada.';
                     onsetIndicator.textContent = '';
                     onsetIndicator.className = 'onset-display';
                     visualizerDiv.style.backgroundColor = '#fff';
                     if(analyzeButton) analyzeButton.disabled = false;
                     sourceNode = null;
                     animationFrameId = null;
                }
            }

             sourceNode.onended = () => {
                 console.log("Playback ended event received.");
                 // Esta función puede llamarse ligeramente antes de que elapsedTime supere la duración
                 // Aseguramos la limpieza final aquí también por si acaso.
                  if (animationFrameId) {
                     cancelAnimationFrame(animationFrameId);
                     animationFrameId = null;
                 }
                 if (!sourceNode) return; // Evitar doble limpieza
                 statusDiv.textContent = 'Reproducción finalizada.';
                 onsetIndicator.textContent = '';
                 onsetIndicator.className = 'onset-display';
                 visualizerDiv.style.backgroundColor = '#fff';
                 if(analyzeButton) analyzeButton.disabled = false;
                 sourceNode = null;
             };

            sourceNode.start(0);
            animationFrameId = requestAnimationFrame(visualizationLoop);
        }

    }); // Fin del listener DOMContentLoaded
        </script>
    


</body>
</html>

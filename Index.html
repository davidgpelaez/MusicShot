<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Analizador de Onsets con Meyda.js</title>
    <script src="https://cdn.jsdelivr.net/npm/meyda@5.6.3/dist/web/meyda.min.js"></script>
    <style>
        body {
            font-family: sans-serif;
            background-color: #f0f0f0;
            color: #333;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        #controls, #status, #visualizer {
            margin: 10px 0;
            padding: 15px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            text-align: center;
        }
        #visualizer {
            min-height: 100px;
            width: 80%;
            max-width: 600px;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 2em;
            font-weight: bold;
            transition: background-color 0.1s ease-out; /* Suave transición de color */
        }
        .onset-display {
             /* Se mostrará texto directamente en #visualizer */
        }
        .grave {
            color: blue;
        }
        .agudo {
            color: red;
        }
         button {
            padding: 10px 15px;
            font-size: 1em;
            cursor: pointer;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.2s;
         }
         button:hover {
             background-color: #0056b3;
         }
         button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
         }
         input[type="file"] {
             margin-bottom: 10px;
         }
    </style>
</head>
<body>

    <h1>Analizador de Onsets Agudos/Graves</h1>

    <div id="controls">
        <input type="file" id="audioFile" accept="audio/mp3, audio/wav, audio/ogg">
        <button id="analyzeButton" disabled>Analizar y Reproducir</button>
    </div>

    <div id="status">Sube un archivo MP3, WAV u OGG.</div>

    <div id="visualizer">
        <span id="onsetIndicator"></span>
    </div>

    <audio id="audioPlayer" style="display: none;"></audio>
    
<script>
    document.addEventListener('DOMContentLoaded', (event) => {
        console.log("Dentro de DOMContentLoaded. ¿Existe Meyda?:", window.Meyda);

        const audioFile = document.getElementById('audioFile');
        const analyzeButton = document.getElementById('analyzeButton');
        const statusDiv = document.getElementById('status');
        const visualizerDiv = document.getElementById('visualizer');
        const onsetIndicator = document.getElementById('onsetIndicator');
        const audioPlayer = document.getElementById('audioPlayer');

        let audioContext;
        let audioBuffer;
        let detectedOnsets = [];
        let meydaAnalyzer;
        let sourceNode;
        let animationFrameId;

        // --- Parámetros Ajustables (Usando SPECTRAL FLUX) ---
        // Generales
        const SPECTRAL_CENTROID_THRESHOLD = 1000; // Hz. Umbral Agudo/Grave (AJUSTAR)
        const MEYDA_BUFFER_SIZE = 1024;
        const DISPLAY_DURATION = 150; // ms
        const DEBOUNCE_TIME = 0.075; // (Segundos) Tiempo mínimo entre onsets detectados (AJUSTAR)

        // Para detección basada en SPECTRAL FLUX
        const FLUX_THRESHOLD = 0.3; // Umbral mínimo de Spectral Flux (AJUSTAR MUCHO - prueba valores entre 0.1 y 1.0 o más)
        const FLUX_PEAK_MULTIPLIER = 1.5; // Factor de pico para Flux (AJUSTAR - prueba entre 1.2 y 2.5)
        // ----------------------------------------------------


        function initAudioContext() {
            if (!audioContext) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log("AudioContext iniciado.");
                } catch (e) {
                    statusDiv.textContent = 'Error: La Web Audio API no es soportada por este navegador.';
                    console.error(e);
                }
            }
        }

        audioFile.addEventListener('change', () => {
            initAudioContext();
            if (audioFile.files.length > 0 && audioContext) {
                analyzeButton.disabled = false;
                statusDiv.textContent = 'Archivo listo para analizar.';
            } else {
                analyzeButton.disabled = true;
            }
        });

        analyzeButton.addEventListener('click', async () => {
            if (!audioFile.files.length || !audioContext) return;
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            analyzeButton.disabled = true;
            statusDiv.textContent = 'Leyendo archivo...';
            const file = audioFile.files[0];
            const reader = new FileReader();

            reader.onload = async (e) => {
                try {
                    statusDiv.textContent = 'Decodificando audio...';
                    audioBuffer = await audioContext.decodeAudioData(e.target.result);
                    statusDiv.textContent = 'Audio decodificado. Analizando onsets (con Spectral Flux)...'; // Mensaje actualizado
                    await analyzeOnsets(); // Usará la nueva lógica de Flux
                    statusDiv.textContent = `Análisis completo. ${detectedOnsets.length} onsets detectados. Reproduciendo...`;
                    console.log("Onsets detectados:", detectedOnsets);
                    startPlaybackAndVisualization();
                } catch (error) {
                    statusDiv.textContent = `Error procesando el audio: ${error.message}`;
                    console.error('Error en reader.onload:', error);
                    analyzeButton.disabled = false;
                }
            };
            reader.onerror = (error) => {
                statusDiv.textContent = 'Error leyendo el archivo.';
                console.error('Error FileReader:', error);
                analyzeButton.disabled = false;
            };
            reader.readAsArrayBuffer(file);
        });

        // *** Función analyzeOnsets MODIFICADA para usar Spectral Flux ***
        async function analyzeOnsets() {
            detectedOnsets = [];
            if (!audioBuffer) return;

            const offlineContext = new OfflineAudioContext(
                audioBuffer.numberOfChannels,
                audioBuffer.length,
                audioBuffer.sampleRate
            );
            const offlineSource = offlineContext.createBufferSource();
            offlineSource.buffer = audioBuffer;

            try {
                console.log("Intentando crear MeydaAnalyzer (usando Spectral Flux)...");
                meydaAnalyzer = Meyda.createMeydaAnalyzer({
                    audioContext: offlineContext,
                    source: offlineSource,
                    bufferSize: MEYDA_BUFFER_SIZE,
                    // Pedimos spectralFlux y spectralCentroid
                    featureExtractors: ["spectralFlux", "spectralCentroid"],
                    callback: features => {
                        if (typeof meydaAnalyzer.lastFlux === 'undefined') {
                            meydaAnalyzer.lastFlux = 0;
                        }
                        const currentFlux = features.spectralFlux;
                        const spectralCentroid = features.spectralCentroid;
                        const timestamp = (meydaAnalyzer.framesElapsed * MEYDA_BUFFER_SIZE) / audioBuffer.sampleRate;
                        let detectedThisFrame = null;

                        // Log para ayudar a tunear umbrales de Flux
                        // console.log(`Flux: ${currentFlux.toFixed(3)} @${timestamp.toFixed(2)}s`);

                        // *** DETECCIÓN BASADA EN SPECTRAL FLUX ***
                        if (currentFlux > FLUX_THRESHOLD && currentFlux > meydaAnalyzer.lastFlux * FLUX_PEAK_MULTIPLIER) {
                            // La clasificación sigue usando el centroide espectral
                            const onsetType = spectralCentroid > SPECTRAL_CENTROID_THRESHOLD ? 'agudo' : 'grave';
                            console.log(`Onset por FLUX -> Tipo: ${onsetType}, Flux: ${currentFlux.toFixed(3)}, Centroide: ${spectralCentroid.toFixed(0)} @${timestamp.toFixed(2)}s`);
                            detectedThisFrame = { timestamp: timestamp, type: onsetType };
                        }

                        // Aplicar Debounce y guardar si se detectó algo
                        if (detectedThisFrame) {
                            const lastOnset = detectedOnsets[detectedOnsets.length - 1];
                            if (!lastOnset || detectedThisFrame.timestamp > lastOnset.timestamp + DEBOUNCE_TIME) {
                                detectedOnsets.push(detectedThisFrame);
                            } else {
                                // console.log(`Onset (Flux) descartado por debounce @${detectedThisFrame.timestamp.toFixed(2)}s`);
                            }
                        }

                        meydaAnalyzer.lastFlux = currentFlux; // Guardar el flux actual
                        meydaAnalyzer.framesElapsed = (meydaAnalyzer.framesElapsed || 0) + 1;
                    }
                });
                console.log("MeydaAnalyzer (Flux) creado con éxito.");

            } catch (e) {
                console.error("ERROR al crear MeydaAnalyzer:", e);
                statusDiv.textContent = "Error fatal: Fallo al inicializar Meyda.";
                throw e;
            }

            meydaAnalyzer.start();
            offlineSource.start(0);

            return offlineContext.startRendering().then(() => {
                meydaAnalyzer.stop();
                console.log("Análisis offline (Flux) completado.");
            }).catch(err => {
                console.error("Error durante el análisis offline:", err);
                statusDiv.textContent = 'Error durante el análisis offline.';
            });
        }


        // *** Función startPlaybackAndVisualization (sin cambios respecto a la última versión completa) ***
        function startPlaybackAndVisualization() {
            if (sourceNode) {
                try { sourceNode.stop(); } catch(e) {}
            }
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }

            sourceNode = audioContext.createBufferSource();
            sourceNode.buffer = audioBuffer;
            sourceNode.connect(audioContext.destination);

            const startTime = audioContext.currentTime;
            let onsetIndex = 0;

            function visualizationLoop() {
                if (!sourceNode) return;

                const elapsedTime = audioContext.currentTime - startTime;

                while (onsetIndex < detectedOnsets.length && detectedOnsets[onsetIndex].timestamp <= elapsedTime) {
                    const onset = detectedOnsets[onsetIndex];
                    onsetIndicator.textContent = onset.type.toUpperCase();
                    onsetIndicator.className = `onset-display ${onset.type}`;
                    visualizerDiv.style.backgroundColor = onset.type === 'grave' ? 'rgba(0, 0, 255, 0.2)' : 'rgba(255, 0, 0, 0.2)';

                    setTimeout(() => {
                         const nextOnsetIndex = onsetIndex;
                         const currentTimeCheck = audioContext.currentTime - startTime;
                         if (nextOnsetIndex >= detectedOnsets.length || detectedOnsets[nextOnsetIndex].timestamp > currentTimeCheck) {
                            onsetIndicator.textContent = '';
                            onsetIndicator.className = 'onset-display';
                            visualizerDiv.style.backgroundColor = '#fff';
                         }
                    }, DISPLAY_DURATION);
                    onsetIndex++;
                }

                if (elapsedTime < audioBuffer.duration + 0.1) {
                    animationFrameId = requestAnimationFrame(visualizationLoop);
                } else {
                     statusDiv.textContent = 'Reproducción finalizada.';
                     onsetIndicator.textContent = '';
                     onsetIndicator.className = 'onset-display';
                     visualizerDiv.style.backgroundColor = '#fff';
                     if(analyzeButton) analyzeButton.disabled = false;
                     sourceNode = null;
                     animationFrameId = null;
                }
            }

             sourceNode.onended = () => {
                 console.log("Playback ended event received.");
                  if (animationFrameId) {
                     cancelAnimationFrame(animationFrameId);
                     animationFrameId = null;
                 }
                 if (!sourceNode) return;
                 statusDiv.textContent = 'Reproducción finalizada.';
                 onsetIndicator.textContent = '';
                 onsetIndicator.className = 'onset-display';
                 visualizerDiv.style.backgroundColor = '#fff';
                 if(analyzeButton) analyzeButton.disabled = false;
                 sourceNode = null;
             };

            sourceNode.start(0);
            animationFrameId = requestAnimationFrame(visualizationLoop);
        }

    }); // Fin del listener DOMContentLoaded
</script>
    

</body>
</html>
